% arara: xelatex
\documentclass[12pt]{article}

% Stochastic Processes, 2024-2025

% \usepackage{physics}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\usepackage{tikzducks}

\usepackage{tikz} % картинки в tikz
\usetikzlibrary{shapes, arrows, positioning}
\usepackage{microtype} % свешивание пунктуации

\usepackage{array} % для столбцов фиксированной ширины

\usepackage{indentfirst} % отступ в первом параграфе

\usepackage{sectsty} % для центрирования названий частей
\allsectionsfont{\centering}

\usepackage{amsmath, amsfonts, amssymb} % куча стандартных математических плюшек

\usepackage{comment}

\usepackage[top=2cm, left=1.2cm, right=1.2cm, bottom=2cm]{geometry} % размер текста на странице

\usepackage{lastpage} % чтобы узнать номер последней страницы

\usepackage{enumitem} % дополнительные плюшки для списков
%  например \begin{enumerate}[resume] позволяет продолжить нумерацию в новом списке
\usepackage{caption}

\usepackage{url} % to use \url{link to web}


\newcommand{\smallduck}{\begin{tikzpicture}[scale=0.3]
    \duck[
        cape=black,
        hat=black,
        mask=black
    ]
    \end{tikzpicture}}

\usepackage{fancyhdr} % весёлые колонтитулы
\pagestyle{fancy}
\lhead{Time Series and Stochastic Processes}
\chead{}
\rhead{Home assignments for samurai}
\lfoot{}
\cfoot{}
\rfoot{}

\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\usepackage{tcolorbox} % рамочки!

\usepackage{todonotes} % для вставки в документ заметок о том, что осталось сделать
% \todo{Здесь надо коэффициенты исправить}
% \missingfigure{Здесь будет Последний день Помпеи}
% \listoftodos - печатает все поставленные \todo'шки


% более красивые таблицы
\usepackage{booktabs}
% заповеди из докупентации:
% 1. Не используйте вертикальные линни
% 2. Не используйте двойные линии
% 3. Единицы измерения - в шапку таблицы
% 4. Не сокращайте .1 вместо 0.1
% 5. Повторяющееся значение повторяйте, а не говорите "то же"


\setcounter{MaxMatrixCols}{20}
% by crazy default pmatrix supports only 10 cols :)


\usepackage{fontspec}
\usepackage{libertine}
\usepackage{polyglossia}

\setmainlanguage{russian}
\setotherlanguages{english}

% download "Linux Libertine" fonts:
% http://www.linuxlibertine.org/index.php?id=91&L=1
% \setmainfont{Linux Libertine O} % or Helvetica, Arial, Cambria
% why do we need \newfontfamily:
% http://tex.stackexchange.com/questions/91507/
% \newfontfamily{\cyrillicfonttt}{Linux Libertine O}

\AddEnumerateCounter{\asbuk}{\russian@alph}{щ} % для списков с русскими буквами
% \setlist[enumerate, 2]{label=\asbuk*),ref=\asbuk*}

%% эконометрические сокращения
\DeclareMathOperator{\Cov}{\mathbb{C}ov}
\DeclareMathOperator{\Corr}{\mathbb{C}orr}
\DeclareMathOperator{\Var}{\mathbb{V}ar}
\DeclareMathOperator{\col}{col}
\DeclareMathOperator{\row}{row}

\let\P\relax
\DeclareMathOperator{\P}{\mathbb{P}}

\DeclareMathOperator{\E}{\mathbb{E}}
% \DeclareMathOperator{\tr}{trace}
\DeclareMathOperator{\card}{card}

\DeclareMathOperator{\Convex}{Convex}
\DeclareMathOperator{\plim}{plim}

\newcommand{\cF}{\mathcal{F}}
\newcommand{\cH}{\mathcal{H}}



\newcommand{\cN}{\mathcal{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\hb}{\hat{\beta}}


\usepackage{mathtools}

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\scalp}{\langle}{\rangle}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}



\begin{document}

Be brave! You can use python. In this case just provide the code. 
You can use ChatGPT or any other LLM. In this case just provide the full prompt. 
Don't panic!


\section*{Home assignment 1}


Deadline: 2024-09-23, 21:00.

\begin{enumerate}
\item The Cat can be only in two states: Sleeping ($S$) and Eating ($E$). 
Cat's mood depends only on the previous state. 
The transition probabilities are given below:

%\begin{minipage}
\begin{tikzpicture}[->,>= stealth', shorten >=2pt , line width=0.5pt, node distance=2cm]
    \node [circle, draw] (one) {$E$};
    \node [circle, draw] (two) [right of=one] {$S$};
    \path (one) edge [bend left] node [above] {$0.1$} (two);
    \path (two) edge [bend left] node [below]{$0.2$} (one);
    \path (two) edge [loop right] node {} (two);
    \path (one) edge [loop left] node {} (one);
\end{tikzpicture}
%\end{minipage}


\begin{enumerate}
    \item Compute the missing probabilities on the graph.
    \item Write down the transition matrix.
    \item Compute $\P(X_3 = \text{Eating} \mid X_0 = \text{Eating})$.
\end{enumerate}

\item Cowboy Joe enters the Epsilon Bar and orders one pint of beer. 
He drinks it and orders one pint more. 
And so on and so on and so on\dots{ }
The problem is that the barmaid waters down each pint with probability $0.2$ independently of other pints.
Joe does not like watered down beer. 
He will blow the Epsilon Bar to hell if two or more out of the last three pints are watered down. 

We point out that Joe never drinks less than 3 pints in a bar. 

\begin{enumerate}
    \item What is the expected number of pints of beer Joe will drink?
\end{enumerate}

Let $Y_t$ be the indicator that the pint number $t$ was watered down. 
Consider the Markov chain $S_t = (y_{t-2}, y_{t-1}, y_t)$.
For example, $S_t = (100)$ means that the pint number $t-2$ was watered down while pints number $t-1$ and $t$ are good. 

\begin{enumerate}[resume]
\item What are the possible values of $S_3$ and their probabilities?
\item Write down the transition matrix of this Markov chain.
\end{enumerate}

Note: questions (2b) and (2c) were updated!

\item Pavel Durov starts at the point $X_0 = 3$ on the real line. 
Each minute he moves left with probability $0.4$ or right with probability $0.6$ independently of past moves.
The points $0$ and $5$ are absorbing. 
If Pavel reaches $0$ or $5$ he stays there forever.
Let $X_t$ be the coordinate of Pavel after $t$ minutes. 

\begin{enumerate}
    \item Write down the transition matrix of this Markov chain. 
    \item Calculate the distribution of $X_7$ [list all values of the random variable $X_7$ and estimate the probabilities].
\end{enumerate}



Hint: you are free to use python for this problem :)


\end{enumerate}


\section*{Home assignment 2}

Deadline: 2024-09-27, 21:00.

\begin{enumerate}
    \item {[10 points]} Consider two identical hedgehogs starting at the vertices $A$ and $B$ of a polygon $ABCD$. 
    Each minute each hedehog simulteneously and independently chooses to go clockwise to the adjacent point, to go counter-clockwise to the adjacent point or to stay at his location.
    
    Thus the brotherhood of two brave hedgehogs can be in three states: in one vertex, 
    in two adjacent vertices, in two non-adjacent vertices.

  
    \begin{enumerate}
      \item Draw the graph for the brotherhood Markov chain and calculate all transition probabilities. 
      \item Write down the transition matrix of the brotherhood Markov chain. 
      \item What is the probability that they will be in one vertex after 3 steps?
    \end{enumerate}
    
    \item {[10 points]} Consider the following Markov chain:

    \begin{tikzpicture}[->,>= stealth', shorten >=2pt , line width=0.5pt, node distance=2cm]
        \node [circle, draw] (one) {$A$};
        \node [circle, draw] (two) [right of=one] {$B$};
        \node [circle,  draw] (three) [right of=two] {$C$};
        \path (one) edge [bend left] node [above] {$0.3$} (two);
        \path (two) edge [bend right] node [below] {$0.3$} (three);
        \path (two) edge [bend left] node [below]{$0.7$} (one);
        \path (three) edge [loop right] node {$0.2$} (three);
        \path (three) edge [bend right] node [above] {$0.8$} (two);
        \path (one) edge [loop left] node {$0.7$} (one);
    \end{tikzpicture}

    \begin{enumerate}
        \item Find the stationary distribution of this Markov chain.
    \end{enumerate}
    
    The Markov chains starts at the vertex $A$.
    Let $N$ be the first moment when the state $C$ will be reached.

    \begin{enumerate}[resume]
      \item Find the expected value $\E(N)$.
      \item Find the variance $\Var(N)$. 
    \end{enumerate}

    \item {[10 points]} Bonnie and Clyde start at the points $(5, 0)$ and $(-5, 0)$ of the plane. 
    Each minute each of them simulteneously and independently makes one step in one of the four possible directions (south, north, east, west).

    Each of them does $n$ steps.
    Let $X$ be the number of times they will be at the same point.
    \begin{enumerate}
        \item Estimate the probability $\P(X \geq 1)$ for $n=50$ using $B=10000$ simulations. 
        \item Estimate $\E(X)$ and $\Var(X)$ for $n=50$ using $B=10000$ simulations. 
        \item Plot the estimated value of $\E(X)$ as a function of $n$ for $n$ from $1$ to $200$ using $B=10000$ simulations. 
    \end{enumerate}

\end{enumerate}




\section*{Home assignment 3}

Deadline: 2024-10-04, 23:59.

\begin{enumerate}
    \item {[10 points]} We randomly wander on the graph choosing at each moment of time one of the possible directions equiprobably.
    
    \begin{tikzpicture}[->,>= stealth', shorten >=2pt , line width=0.5pt, node distance=2cm]
        \node [circle, draw] (A) {$a$};
        \node [circle, draw] (B) [right of=A] {$b$};
        \node [circle, draw] (C) [right of=B] {$c$};
        \node [circle, draw] (D) [below of=A] {$d$};
        \node [circle, draw] (E) [right of=D] {$e$};
        \node [circle, draw] (F) [right of=E] {$f$};
        \node [circle, draw] (G) [right of=C] {$g$};
      
      
        \path (A) edge (D);
        \path (D) edge (E);
        \path (E) edge (A);
        \path (B) edge (E);
        \path (B) edge (C);
        \path (C) edge (F);
        \path (C) edge (G);
        \path (F) edge (B);
      
      
        \path (D) edge [loop left] (D);
        \path (E) edge [loop right] (E);
        \path (G) edge [loop below] (G);
    \end{tikzpicture}
    \begin{enumerate}
        \item Split each Markov chain into communicating classes. 
        \item Find the period of every state. 
        \item Classify each state as transient or recurrent.
        \item For recurrent states find the expected return time.
        \item Find the stationary distributions. 
    \end{enumerate}
        
    
    
    \item {[10 points]} Design a Markov chain with 3 states and unique stationary distribution $\pi = (0.1, 0.2, 0.7)$.

    \item {[10 points]} Consider three games:
    \begin{enumerate}
        \item[Game A:] You toss a biased coin with probability $0.48$ of $H$. 
        You get $+1$ dollar for $H$ and $-1$ dollar for $T$.  

        \item[Game B:] If your wellfare is divisible by three you toss a coin that
        lands on $H$ with probability $0.09$. 
        If your wellfare is not divisible by three you toss a coin that lands on $H$ with probability $0.74$.
        You get $+1$ dollar for $H$ and $-1$ dollar for $T$.  
        
        \item[Game C:] You toss an unbiased coin.
        If it lands on $H$ you play Game A. If it lands on $T$ you play Game B. 
    \end{enumerate}
    
    Your initial capital is $10000\$$.

    \begin{enumerate}
        \item Generate and plot two random trajectories of your wellfare if you play Game A $10^6$ times.
        \item Generate and plot two random trajectories of your wellfare if you play Game B $10^6$ times.
        \item Generate and plot two random trajectories of your wellfare if you play Game C $10^6$ times.
    \end{enumerate}

% game_a = function(x) {
% a = sample(c(-1, +1), size = 1, prob = c(0.52, 0.48))
% return(x + a)
% }

% game_b = function(x) {
% a = sample(c(-1, +1), size = 1, prob = c(0.25, 0.75))
% b = sample(c(-1, +1), size = 1, prob = c(0.91, 0.09))
% if ((x %% 3) == 0) {
%     res = x + b
% } else {
%     res = x + a
% }
% return(res)
% }

% game_c = function(x) {
% a = sample(c(-1, +1), size = 1, prob = c(0.5, 0.5))
% if (a == 1) {
%     res = game_a(x)
% } else {
%     res = game_b(x)
% }
% return(res)
% }  
    
% w = 100
% for (i in 1:1000000) {
% print(w)
% w = game_b(w)
% }
      


\end{enumerate}


\section*{Home assignment 4}

Deadline: 2024-10-14, 23:59.

\begin{enumerate}
    \item Recognise the distribution family and its parameters by looking at the moment-generating function:
    
    \begin{enumerate}
        \item $0.7 + 0.3\exp(t)$;
        \item $\exp(2024\exp(t)) / \exp(2024)$;
        % \item $\frac{\exp(3t) - 1}{3t\exp(-2t)}$;
        \item $\exp(6t + 2024t^2)$;
        \item $1/(5t - 1)^{2024}$.
    \end{enumerate}
    
    You may use the table from the article 
    
    \url{https://en.wikipedia.org/wiki/Moment-generating_function}.
    
    \item Consider the moment-generating function of a random variable $X$:
    \[
     g(t) = \frac{\exp(3t) - 1}{3t\exp(-2t)}.
    \]
    
    \begin{enumerate}
        \item Expand the function $g(t)$ as Taylor series up to $t^4$ included. 
        \item Find $\E(X)$, $\E(X^2)$, $\E(X^3)$, $\E(X^4)$.
    \end{enumerate}


    \item The moment-generating function of the pair of random variables $(X, Y)$ is given by 
    $\exp(6t_1 + 5t_2 + t_1^2 + 20t_2^2 - 2t_1t_2)$.

    Find $\E(X)$, $\Var(Y)$, $\E(XY)$.
    
\end{enumerate}



\section*{Home assignment 5}

Deadline: 2024-10-18, 23:59.

\begin{enumerate}

\item {[10 points]} The random variables $X_i$ are independent and exponentially distributed with rate $\lambda = 1$. 

\begin{enumerate}
    \item Find the probability limit
    \[
    \plim \frac{X_1 + X_2 + X_3 + \dots + X_n}{2n + 7}.
    \]
    \item Find the probability limit
    \[
    \plim \frac{X_1^2 + X_2^2 + X_3^2 + \dots + X_n^2}{2n + 7}.
    \]
    \item Find the probability limit
    \[
        \plim \min\{X_1, X_2, X_3, \dots, X_n\}.
    \]
    \item Find the probability limit
    \[
    \plim \sqrt[n]{\exp(2X_1 + 2X_2 + \dots + 2X_n)}.
    \]
\end{enumerate}



\item {[10 points]} Polina loves sweet chestnuts. 
She has infinite sequence of baskets before her.
In the basket number~$n$ there are $n$~chestnuts in total.
Unfortunately only one chestnut in every basket is a sweet one. 

She picks chestnuts one by one at random from all the buskets sequentially. 
First she picks the unique chestnut from the basket number one, 
than she picks in a random order two chestnuts from the basket number two and so on. 

The random variable $S_t$ indicates whether the chestnut number $t$ was a sweet one. 

\begin{enumerate}
  \item Find $\lim S_t$ or prove that the limit does not exist.
  \item Find $\plim S_t$ or prove that the limit does not exist.
  \item Find mean square limit of $S_t$ or prove that the limit does not exist. 
\end{enumerate}

\item {[10 points]} Consider two Markov chains, $(X_t)$ and $(Y_t)$: 

\begin{tikzpicture}[->,>= stealth', shorten >=2pt , line width=0.5pt, node distance=3cm]
    \node [circle, draw] (one) {$x = -1$};
    \node [circle, draw] (two) [right of=one] {$x = 0$};
    \node [circle,  draw] (three) [right of=two] {$x = 1$};
    % \path (one) edge [bend left] node [above] {$1$} (two);
    \path (two) edge node [below] {$0.3$} (three);
    \path (two) edge node [below]{$0.7$} (one);
    %\path (three) edge [loop right] node {$0.2$} (three);
    %\path (three) edge [bend right] node [above] {$0.8$} (two);
    \path (one) edge [loop left] node {$1$} (one);
    \path (three) edge [loop right] node {$1$} (three);
\end{tikzpicture} with $X_0 = 0$;

and

\begin{tikzpicture}[->,>= stealth', shorten >=2pt , line width=0.5pt, node distance=3cm]
    \node [circle, draw] (one) {$y = -1$};
    \node [circle, draw] (two) [right of=one] {$y = 0$};
    \node [circle,  draw] (three) [right of=two] {$y = 1$};
    \node [circle,  draw] (four) [right of=three] {$y = 2$};
    % \path (one) edge [bend left] node [above] {$1$} (two);
    \path (two) edge node [below] {$0.3$} (three);
    \path (two) edge node [below]{$0.7$} (one);
    % \path (three) edge [loop right] node {$0.2$} (three);
    \path (three) edge [bend left] node [above] {$0.5$} (four);
    \path (four) edge [bend left] node [above] {$1$} (three);
    \path (one) edge [loop left] node {$1$} (one);
    \path (three) edge [loop below] node {$0.5$} (three);
\end{tikzpicture} with $Y_0 = 0$.



\begin{enumerate}
    \item Find $\P(\lim X_n \text{ exists})$ and $\P(\lim Y_n \text{ exists})$.
    \item Find the limiting distribution of $(X_n)$ and the limiting distribution of $(Y_n)$.

    Hint: here you need to calculate all limits $\lim \P(X_n = k)$, $\lim \P(Y_n = k)$.
    
    \item Does $(X_n)$ converges almost surely? In distribution? In probability?
    \item Does $(Y_n)$ converges almost surely? In distribution? In probability?
\end{enumerate}


\end{enumerate}


\section*{Home assignment 6}

Deadline: 2024-11-01, 23:59.

\begin{enumerate}

\item {[10 points]} Albert Nikolayevich Shiryaev randomly selects a natural number $N$ from $1$ to $7$.
Let $Y$ be the remainder after division of $N$ by $2$ and $X$ be the remainder after division of $N$ by $3$. 

\begin{enumerate}
    \item Write the joint probability table for $(X, Y)$.
    \item Find $\E(Y \mid X)$. Is it linear in $X$?
    % \item Find $\E(X \mid Y)$. Is it linear in $Y$?
    \item Find $\E(\E(Y \mid X))$ and $\Var(\E(Y \mid X))$.
    \item Find $\Var(Y \mid X)$.
    \item Find $\E(\Var(Y \mid X))$.
    % \item Find $\E(\Var(Y \mid X)) + \Var(\E(Y \mid X))$.
\end{enumerate}


\item {[10 points]} Albert Nikolayevich selects a random point uniformly inside a quadrilateral $ABCD$ where $A = (0, 0)$, $B = (0, 2)$,
$C = (4, 4)$, $D = (4, 0)$.

\begin{enumerate}
    \item Find $\E(Y \mid X)$ and $\E(X \mid Y)$.
    \item Find $\Var(Y \mid X)$ and $\Var(X \mid Y)$.
\end{enumerate}

Hint: you may use the formula for the variance of uniform distribution :)

\item {[10 points]} Albert Nikolayevich selects a random point $(X, Y)$ with joint probability density
\[
f(x, y) = \begin{cases}
    (3x^2 + 4y^3) / 2, \text{ if } x \in [0;1], y \in [0;1]; \\
    0, \text{ otherwise}. 
\end{cases}
\]
\begin{enumerate}
    \item For the random variable $x$ find the marginal probability density function $f(x)$.
    %\footnote{%
    %Hereinafter we abuse notation. Strictly speaking we shoud write $f_X(x)$ and $f_Y(y)$ because these are different functions.} 
    \item Find the conditional density $f(y \mid x)$.
    \item Find the conditional expected value $\E(Y \mid X)$. Is it linear in $X$?
    \item Find $\Var(Y \mid X)$. Is it constant?
    \item Find $\E(X)$, $\E(Y)$, $\Cov(X, Y)$ and $\Var(X)$.
    % \item Find the best linear approximation $Y^* = \beta_0 + \beta_1 X$ of the random variable $Y$.
    
    % Hint: Here you should minimize $\E((Y - Y^*)^2)$ with respect to the true constants $\beta_0$ and $\beta_1$.
\end{enumerate}

\end{enumerate}



\section*{Home assignment 7}

Deadline: 2024-11-03, 23:59.

\begin{enumerate}
\item Experiment may end by one of the six outcomes:

\begin{tabular}{*{4}{c}}
\toprule
& $X=-2$ & $X=0$ & $X=2$ \\
\midrule
$Y=-1$ & 0.1 & 0.2 & 0.3  \\
$Y=1$ & 0.2 & 0.1 & 0.1  \\
\bottomrule
\end{tabular}

\begin{enumerate}
  \item Find expicitely the sigma-algebras $\sigma(X)$, $\sigma(Y)$, $\sigma(X \cdot Y)$.
  \item How many elements are there in $\sigma(X + Y)$, $\sigma(X - Y)$?
  \item Calculate conditional expected values $\E(X \mid \sigma(Y))$, $\E(X \mid \sigma(X + Y))$.
\end{enumerate}


\item We throw a coin infinitely many times. 
Let $X_{n}$ be the indicator that the coin landed on Head at toss number $n$.
Consider a pack of $\sigma$-algebras: $\cF_{n}:=\sigma(X_1, X_2, \ldots, X_n)$, $\cH_{n}:=\sigma(X_{n}, X_{n+1}, X_{n+2}, \ldots)$.

\begin{enumerate}
\item Simplify experessions: $\cF_{11}\cap \cF_{25}$, $\cF_{11}\cup \cF_{25}$, $\cH_{11}\cup \cH_{25}$.

\item For each case provide two examples of $\sigma$-algebras that contain the corresponding event
\begin{enumerate}
\item $\{X_{37}>0 \}$;
\item $\{X_{37}>X_{2024} \}$;
\item $\{ X_{37}>X_{2024}>X_{12} \}$;
\end{enumerate}

\item For each case provide two non-trivial examples (different from $\Omega$ and $\emptyset$) of an event $A$ such that

\begin{enumerate}
\item $A\in \cF_{2024}$;
\item $A\notin \cF_{2025}$;
\item $A \in \cH_{n}$ for all possible $n$;
\end{enumerate}


\end{enumerate}

\item Consider a fair dice. 
In the experiment we throw the dice until the first six appears.

\begin{enumerate}
    \item Simulate $B = 100000$ experiments. 
    For every experiment number $i$ record the total number of throws, $y_i$, and the number of even faces appeared, $x_i$.
    \item For all values of $x$ where you have more than $100$ records estimate $\hat\mu(x) = \hat{\E}(y_i \mid x_i = x)$ and $\hat v(x) = \widehat{\Var}(y_i \mid x_i = x)$.
    \item Explain intuitively why $\hat\mu(0)$ is less than $3$. 
    \item Randomly select $100$ experiments out of all $B$ experiments.
    Draw the scatter plot $(x_i, y_i)$ for randomly selected experiments.
    Add the line $\hat\mu(x)$ with bands $\hat\mu(x) \pm 2\sqrt{\hat v(x)}$ to the scatter plot. 
    \item Is it reasonable to assume that $\hat \mu(x)$ is linear?
    \item Is it reasonable to assume that $\hat v(x)$ is constant?
\end{enumerate}

No formal tests are required for the last two questions, graphical analysis is sufficient.


\end{enumerate}

\section*{Home assignment 8}

Deadline: 2024-11-16, 23:59.

\begin{enumerate}
\item The random variables $X_n$ are independent and take values $+1$ with probability $0.7$ or $2$ with probability $0.3$.
Let $S_n = X_1 + X_2 + \dots + X_n$ be the cumulative sum. 

\begin{enumerate}
    \item Find the constant $a$ such that $M_n = S_n - a n$ is a martingale.
    \item Find all constants $b$ such that $K_n = \exp(b S_n)$ is a martingale.
\end{enumerate}

\item The population starts with one microbe Eve.
So the size of the initial generations is $G_0 = 1$. 
After one minute every microbe either dies with probability $0.2$, remains alive with probability $0.5$ or splits in two copies with probability $0.3$.
Let $G_n$ be the size of microbe population after $n$ minutes.

\begin{enumerate}
    \item Draw a pretty picture of Eve :)
    \item Find the distribution of $G_2$. 
    \item Find a constant $a$ such that $M_n = G_n /a^n$ is a martingale. 
    \item Let $D$ be the event of eventual death of the microbe civilization. 
    Check whether the process $K_n = \E(I_D \mid G_n, G_{n-1}, \dots, G_0)$ is martingale. 
    Here $I_D$ is the indicator of the event $D$.
    \item Using first step analysis find $\P(D)$.
    
    Hint: you may obtain a quadratic equation for $\P(D)$, the smallest root is your friend :)
\end{enumerate}

\item Consider a symmetric random walk $S_t = X_1 + X_2 +\dots + X_t$ where $(X_t)$ are
independent identically distributed and take values $+1$ or $-1$ with equal probabilities.
We start at zero, $S_0 = 0$.

Let $N_k$ the number of visits of point $k$ before the first return of a random walk to $0$.

\begin{enumerate}
    \item What is the probability that a random walk will eventually return to $0$?
    \item What is the probability $\P(N_k = 0)$?
    \item What is the probability $\P(N_k = n)$ for arbitrary natural number $n$?
    \item Compare $\E(N_2)$ and $\E(N_{\text{undecillion}})$.
\end{enumerate}



\end{enumerate}


\section*{Home assignment 9}

Deadline: 2024-12-03, 23:59.


\begin{enumerate}
    \item It's $X_0 = -35^{\circ}C$ today in Oymyakon. 
    Each day the daily temperature $(X_t)$ may go up or down by $2^{\circ}$ degrees with equal probability independently of the previous days. 
 
    Initially my piggy-bank is empty, $B_t = 0$. 
    Each day I add in my piggy-bank $\abs{X_t}$ undecillion roubles, $B_{t} = B_{t-1} + \abs{X_t}$.
    I will do my final investment in the piggy-bank when the temperature in Oymyakon will reach $-45^{\circ}C$ or $-25^{\circ}C$.
    At the end of this day $\tau$ I will break the piggy-bank and go for vacations in Oymyakon. 

    \begin{minipage}{0.9\textwidth}
        \includegraphics[scale=0.35]{figures/piggy.png}        
    \end{minipage}


    \begin{enumerate}
        \item Is $(X_t)$ a martingale?
        \item Using $(X_t)$ and Doob's theorem or otherwise find $\P(X_{\tau} = -25)$.
        \item Find a constant $a$ such that $Y_t = X^2_t - a t$ is a martingale.
        \item Using $(Y_t)$ and Doob's theorem find $\E(\tau)$.
        \item Find a constant $b$ such that $W_t = B_t + b X_t t$ is a martingale. 
        \item Find my expected final wellfare $\E(B_{\tau})$.
    \end{enumerate}

    Comment: you may not check technical conditions of the Doob's theorem.

    \item Consider a Poisson point process $(X_t)$ of snowflakes falling in my palm with intensity $\lambda = 0.5$ snowflakes per second.
    \begin{enumerate}
    %    \item Я только что раскрыл ладошку. Какова вероятность того, что следующая снежинка упадёт раньше, чем через три секунды?
        \item What is the probability that in $5$ I will catch two or more snowflakes?
        \item I've just opened my palm. What is the probability that the next two snowflakes will fall in less than three seconds?
        \item Find conditional probability $\P(X_{10} = 5 \mid X_{4} = 1)$.
        \item Find conditional expected value $\E(X_{10} \mid X_{4} = 1)$ and variance $\Var(X_{10} \mid X_4 = 1)$.
    \end{enumerate}
    
    \item Insurance claims arrive according to Poisson process with intensity $100$ claims per month. 
The payments for each claim are independent random variables uniformly distributed between $0$ and $1$ undecillion roubles. 
    
    Simulate $10^4$ trajectories of this process with monthly duration.
    
    \begin{enumerate}
        \item Draw the histogram of total payments for $10$ days. 
        \item Estimate the probability that the total payments for $10$ will be more than $12$ undecillion roubles. 
        \item Estimate reserves necessary for the company that are sufficient to cover all the claims with probability $0.05$.
        \item Recalculate estimates in (b) and (c) if every saturday and sunday the intensity drops from $100$ to $10$ and 
        the month starts from monday. 
    \end{enumerate}
    
\end{enumerate}

\section*{Home assignment 10}

Deadline: 2024-12-14, 23:59.

\begin{enumerate}

    \item Let $(W_t)$ be a standard Wiener process.

    \begin{enumerate}
        \item Calculate $\E(W_9 - 2W_6)$, $\Var(W_9 - 2W_6)$, $\P(W_9 - 2W_6 > 1)$.
        \item Calculate $\E(W_9 - 2W_6 \mid W_1 = 1)$, $\Var(W_9 - 2W_6 \mid W_1 = 1)$, $\P(W_9 - 2W_6 > 1 \mid W_1 = 1)$.
        \item Calculate $\Cov(W_9, W_6 - W_1)$ and $\Cov(W_9, W_6 - W_1 \mid W_1 = 1)$.
    \end{enumerate}

    Remark: we will include a similar problem in the exam. 


    \item Let $(W_t)$ be a standard Wiener process.
    Consider three more processes, $R_t = W_t^6 \cos t$, $X_t = Y_t^3 + t^2 Y_t$ and $dY_t = W_t^2 dW_t + tW_t dt$ with $Y_0 = 1$.
    \begin{enumerate}
        \item Find $dR_t$ and $dX_t$.
        \item Represent the process $R_t$ as a sum of an Ito integral and a Riemann integral.
        \item Check whether $X_t$ is a martingale. 
        \item Find $\E(Y_t)$.
        \item Find $\Var(Y_t)$. Hint: find $d(Y_t^2)$ and calculate $\E(Y_t^2)$.
    \end{enumerate}


    \item In the framework of Black and Scholes model find the price at $t=0$ of the following two 
    financial assets, $dS_t = \mu S_t dt + \sigma S_t dW_t$ is the share price equation. 
    \begin{enumerate}
      \item The asset pays you at time $T$ exactly one dollar if $S_T < K$ where $K$ is a constant 
      specified in the contract. 
      \item The asset pays you at time $T$ exactly $S_T^2$ dollars.
    \end{enumerate}
  

\end{enumerate}


% \chapter{2025}

\section*{Home assignment 11}

Deadline: 2025-02-04, 23:59.

\begin{enumerate}

\item Consider a process $y_t = 6 + u_t - 0.5 u_{t-1} + 0.06 u_{t-2}$ where $(u_t)$ is a white noise process with variance $\sigma^2_u$.
\begin{enumerate}
    \item Find the expected value $\E(y_t)$ and the autocorrelation function $\rho_k$ of this process. 
    \item Is $(y_t)$ weakly stationary? Is $(y_t)$ invertable with respect to $(u_t)$?
    \item If $(y_t)$ is invertable with respect to $(u_t)$ then find $\alpha$, $\delta_1$ and $\delta_2$ in the expression 
    \[
    u_t = \alpha  + y_t + \delta_1 y_{t-1} + \delta_2 y_{t-2} + \dots. 
    \]
\end{enumerate}
    
\item Consider the equation $y_t = 2 + 0.8 y_{t-1} + u_t$ where $(u_t)$ is a white noise with variance $\sigma^2_u$.
    \begin{enumerate}
        \item Find the stationary solution $(y_t)$ in terms of $u_t$, $u_{t-1}$, $u_{t-2}$, \dots. 
        \item Find the expected value $\E(y_t)$ and autocorrelation function of the stationary solution. 
        \item Find at least one initial value $y_0$ such that $\E(y_2) = -4$. Is the process with such $y_0$ stationary?
        \item How many non-stationary solution are there?
    \end{enumerate}

    \item Consider the processes $a_t = u_1 \cos(t) + u_2 \sin (t)$ and $b_t = 7 + u_t + (-1)^t u_{t-1}$ 
    where $(u_t)$ is a white noise with variance $\sigma^2_u$.

    \begin{enumerate}
        \item Check whether each process, $(a_t)$ and $(b_t)$, is stationary. 
        \item For a stationary process find the autocorrelation function and expected value. 
    \end{enumerate}

    % Provide an example of a process that is simulteneously Markov chain and stationary but not a martingale.



\end{enumerate}




\end{document}

